{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a869a294-2245-4ddf-8d32-9fa05568ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import random\n",
    "from joblib import load\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b69b60-6424-47f5-af12-880d338c7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_loc = ['HMB_1','HM_2','HM_4','HMB_5','HMB_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88751573-b1f6-447c-bb1c-f13f3e6b78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_image(dataframe, images_location):\n",
    "    dfs = []\n",
    "    for frame, image_dir in zip(dataframes, images_location):\n",
    "\n",
    "        # Attaching image files to the inputs\n",
    "        image_base_dir = f'./Data/ROSBAG/Ch2_002/images/{image}'\n",
    "            \n",
    "        # Define camera folders\n",
    "        camera_folders = {\n",
    "                \"left\": os.path.join(image_base_dir, \"left\"),\n",
    "                \"center\": os.path.join(image_base_dir, \"center\"),\n",
    "                \"right\": os.path.join(image_base_dir, \"right\"),\n",
    "            }\n",
    "            \n",
    "        # Create new columns for each camera\n",
    "        for camera, folder in camera_folders.items():\n",
    "            column_name = f'{camera}_image_path'\n",
    "            image_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "                \n",
    "            # Add the image paths to the DataFrame\n",
    "            frame[column_name] = pd.Series(image_files)\n",
    "\n",
    "        # Drop any inputs that do not have images\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    dfs.append(frame)\n",
    "        \n",
    "    updated_dataframe = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return updated_dataframe\n",
    "imu_hmb_1 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_1/imu-data.csv')\n",
    "imu_hmb_2 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_2/imu-data.csv')\n",
    "imu_hmb_4 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_4/imu-data.csv')\n",
    "imu_hmb_5 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_5/imu-data.csv')\n",
    "imu_hmb_6 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_6/imu-data.csv')\n",
    "imu_dfs = [imu_hmb_1,imu_hmb_2,imu_hmb_4,imu_hmb_5,imu_hmb_6]\n",
    "imu_all = attach_image(imu_dfs,image_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869288a1-f675-4590-939e-eca40eac2fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_imu_csv(df,filename):\n",
    "    df = df.drop(columns = ['header.seq','header.stamp.secs','header.stamp.nsecs', 'header.frame_id'])\n",
    "    df.to_csv(f'./Data/cleaned_data/{filename}.csv', index = False)\n",
    "    return df\n",
    "imu_all = clean_imu_csv(imu_all,'imu_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba0580-2639-4b8a-9273-ad76f25a5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_with_labels(df, image_columns, label_columns, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Prepares X (images) and y (labels) for training a CNN.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing image paths and labels.\n",
    "        image_columns (list): List of column names with image paths (e.g., ['left_image_path', 'center_image_path', 'right_image_path']).\n",
    "        label_columns (list): List of column names for labels (e.g., ['steering_angle', 'throttle_cp']).\n",
    "        target_size (tuple): Target size for resizing images (width, height).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of image data (X).\n",
    "        np.ndarray: Array of labels (y).\n",
    "    \"\"\"\n",
    "    X_images = []\n",
    "    y_labels = []\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        row_images = []\n",
    "        \n",
    "        # Process images for the current row\n",
    "        for col in image_columns:\n",
    "            image_path = row[col]\n",
    "\n",
    "            print(f\"Looking for image: {image_path}\")\n",
    "            \n",
    "            if os.path.exists(image_path):\n",
    "                print(f'Found image path {image_path}')# Ensure file exists\n",
    "                try:\n",
    "                    img = Image.open(image_path).resize(target_size)  # Open and resize\n",
    "                    img_array = np.array(img) / 255.0  # Normalize\n",
    "                    row_images.append(img_array)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"Image not found: {image_path}\")\n",
    "        \n",
    "        # Check if all images for the row are processed\n",
    "        if len(row_images) == len(image_columns):\n",
    "            # Combine images if using multiple cameras\n",
    "            combined_images = np.concatenate(row_images, axis=-1)  # Shape: (height, width, 3 * number of cameras)\n",
    "            X_images.append(combined_images)\n",
    "            \n",
    "            # Collect the corresponding labels\n",
    "            y_labels.append(row[label_columns].values)\n",
    "            \n",
    "    df.set_index('Time', inplace = True)\n",
    "    \n",
    "    # Convert to NumPy arrays\n",
    "    X = np.array(X_images, dtype=np.float32)\n",
    "    y = np.array(y_labels, dtype=np.float32)\n",
    "    \n",
    "    return X, y\n",
    "X, y = prepare_data_with_labels(steer,['left_image_path', 'center_image_path', 'right_image_path'],imu_all.columns[1:37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c51d5-a6c4-44f7-8464-a0e1cf0d1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_imu_all, \"./Data/saved_variables/X_imu_all.pkl\")\n",
    "dump(y_imu_all, \"./Data/saved_variables/y_imu_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e1e78-d3a2-4705-8e03-a63a354a012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imu_model(input_shape):\n",
    "    model = Sequential()\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # First convolutional block\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Second convolutional block\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Third convolutional block\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Fourth convolutional block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Fifth convolutional block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Sixth convolutional block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=37, activation='linear'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X_train,y_train,\n",
    "                       validation_data = (X_test,y_test),\n",
    "                       epochs = 50,\n",
    "                        callbacks = early_stopping,\n",
    "                       batch_size = 128)\n",
    "\n",
    "    return model, history\n",
    "    \n",
    "input_shape = (224,224,9)\n",
    "model, history = create_imu_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce74ad-2c2a-442e-adec-feab3b0f77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc50e75-c354-4461-a085-b76651084191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Data/full_models/imu_all.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2358c28-b219-4abe-a55f-f1b5fa6bafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_image(dataframe, images_location):\n",
    "    dfs = []\n",
    "    for frame, image_dir in zip(dataframes, images_location):\n",
    "\n",
    "        # Attaching image files to the inputs\n",
    "        image_base_dir = f'./Data/ROSBAG/Ch2_002/images/{image}'\n",
    "            \n",
    "        # Define camera folders\n",
    "        camera_folders = {\n",
    "                \"left\": os.path.join(image_base_dir, \"left\"),\n",
    "                \"center\": os.path.join(image_base_dir, \"center\"),\n",
    "                \"right\": os.path.join(image_base_dir, \"right\"),\n",
    "            }\n",
    "            \n",
    "        # Create new columns for each camera\n",
    "        for camera, folder in camera_folders.items():\n",
    "            column_name = f'{camera}_image_path'\n",
    "            image_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "                \n",
    "            # Add the image paths to the DataFrame\n",
    "            frame[column_name] = pd.Series(image_files)\n",
    "\n",
    "        # Drop any inputs that do not have images\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    dfs.append(frame)\n",
    "        \n",
    "    updated_dataframe = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return updated_dataframe\n",
    "brake_hmb_1 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_1/vehicle-brake_info_report.csv')\n",
    "brake_hmb_2 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_2/vehicle-brake_info_report.csv')\n",
    "brake_hmb_4 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_4/vehicle-brake_info_report.csv')\n",
    "brake_hmb_5 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_5/vehicle-brake_info_report.csv')\n",
    "brake_hmb_6 = pd.read_csv('./Data/ROSBAG/Ch2_002/HMB_6/vehicle-brake_info_report.csv')\n",
    "brake_dfs = [brake_hmb_1,brake_hmb_2,brake_hmb_4,brake_hmb_5,brake_hmb_6]\n",
    "brake_all = attach_image(brake_dfs,image_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1703c6-8ecf-4280-8104-9218bf6edbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_brake_csv(df,filename):\n",
    "    df['stationary'] = df['stationary'].astype(int) \n",
    "    df = df[['Time','brake_torque_actual','wheel_torque_actual','accel_over_ground','stationary']]\n",
    "    df.to_csv(f'./Data/cleaned_data/{filename}.csv',index = False)\n",
    "    return df\n",
    "brake_all = clean_brake_csv(brake_all,'brake_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e186c2-0eb1-47e2-891c-4fca2f2cfd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data_with_labels(brake_all,['left_image_path', 'center_image_path', 'right_image_path'],['brake_torque_actual','wheel_torque_actual','accel_over_ground','stationary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b8318-a321-47e6-b391-433fec2f8e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brake_model(input_shape):\n",
    "    model = Sequential()\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # First convolutional block\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Second convolutional block\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Third convolutional block\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Fourth convolutional block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Fifth convolutional block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Sixth convolutional block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=3, activation='linear'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X_train,y_train,\n",
    "                       validation_data = (X_test,y_test),\n",
    "                       epochs = 50,\n",
    "                        callbacks = early_stopping,\n",
    "                       batch_size = 128)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "input_shape = (224,224,9)\n",
    "model, history = create_brake_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646eef0a-f7c8-4ccb-ae77-309f40dbede9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304eac94-bcc4-4219-bcd5-5ae3fed95b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
